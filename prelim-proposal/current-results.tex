\section{Current Results}

We briefly go over progress made towards addressing RCs from
section \ref{sec:introduction}.

\subsection{Evaluating $\K$ for our approach}

To derive maximum benefit from the $\K$ semantics, it is important that:
\begin{enumerate*}[label=(\roman*)]
  \item the $\K$ semantics is descriptive enough to implement language-specific
    tools such as interpreters, model checkers, etc, and,
  \item $\K$-derived tools compare favorably against their language-specific
    counterparts.
\end{enumerate*}
In \MediK{}'s case, we needed to ensure that the interpreter,
in particular, is appropriate for
use in a \CDSS{}. The concern for performance stems from the fact
that being language-agnostic, $\K{}$ derived tools
cannot accommodate language-specific optimizations.

To evaluate the feasibility of $\K$ semantics and derived tools, we
drew upon our work of defining the semantics of a real-world language
(unrelated to \MediK{}), where the $\K$ semantics and derived tools offer
are viable alternatives to their language-specific counterparts.

In \cite{HildenbrandtCSF18},
we completely defined the semantics of the Ethereum Virtual Machine (EVM)
in $\K{}$. The EVM is a low-level stack-based language
that forms backbone of the Ethereum Blockchain. Unlike \MediK{},
EVM had an existing informal paper-based semantics
called the Yellow Paper \cite{evmYellowpaperUrl},
and a reference implementation in C++ \cite{cppEthereumUrl}.
This allowed us to compare the $\K$ based semantics
and interpreter against mature language-specific ones.

We based our $\K$ semantics on the Yellow Paper, and
found several inconsistencies that were confirmed by its developers \cite{HildenbrandtCSF18}.
This stems from the fact that unlike the $\K$ semantics,
the Yellow Paper is an informal document in natural language.
Often, the Yellow Paper was found to be unclear, underspecified
or inconsistent with the behavior of actual implementations.
As the $\K$ semantics are executable, all details have to
considered for our interpreter to pass all tests in the reference
test-suite. We utilized the developer documentation for our semantics
to generate an alternative to the Yellow Paper itself, called the Jello Paper
\cite{evmJellopaperUrl}. The Jello Paper has been well-received by the
community, with discussions to designate it as the \emph{canonical document}
instead of the Yellow Paper. For more details, we refer the reader to
section VII of \cite{HildenbrandtCSF18}.

\begin{wrapfigure}{l}{0.6\textwidth}
      \begin{tabular}{ l l l l }
          \textbf{Test Set} (no. tests) & \textbf{Lem EVM} & \textbf{KEVM} & \textbf{cpp-ethereum} \\
          Lem (40665)                   & 288:39           & 34:23         & 3:06                  \\
          VMStress (18)                 & -                & 72:31         & 2:25                  \\
          VMNormal (40665)              & -                & 27:10         & 2:17                  \\
          VMAll (40683)                 & -                & 99:41         & 4:42                  \\
          GSNormal(22705)               & -                & 35:00         & 1:30                  \\
          GSQuad (250)                  & -                & 855:24        & 0:21                  \\
          GSAll (22955)                 & -                & 889:00        & 1:51                  \\
      \end{tabular}
  \caption{Lem EVM vs KEVM vs cpp-ethereum}\label{fig:evm-comparison}
\end{wrapfigure}
\figurename{} \ref{fig:evm-comparison} compares the $\K{}$-generated interpreter
against the reference implementation (\textbf{cpp-ethereum}) and
another formalization (\textbf{Lem EVM}) of the EVM semantics \cite{HiraiWSTC17} in Lem \cite{MulliganACM14}
on the official test that implementations are expected to pass.
All execution times are given as the full sequential CPU time (in MM:SS format) on an Intel i5-3330 processor (3GHz on 4 hardware threads) and 24 GB of RAM.
By comparing to the C++ reference implementation, we show the feasibility of using the KEVM formal semantics for prototyping, development, and test-suite evaluation.

The row Lem indicates a run of all the tests that the Lem semantics can run (a subset of the VMTests).
The row VMStress indicates a run of all 18 stress tests in the test-suite, to compare the performance of KEVM with the C++ implementation.
The row VMNormal is a run of all the non-stress tests in the test-suite (\textit{not} the same set of tests as Lem).
VMAll is the addition of the second and third rows and is included for completeness.
The last three rows indicate a runs of the GeneralStateTests; GSNormal are the non-stress tests, GSQuad are the stress tests, and GSAll is the addition of the two.
Under the GeneralStateTests, our tools performs well except in the case of QuadraticStateTests (250 out of 22955).

As shown in the comparison, not only did the $\K$ generated interpreter significantly
outperformed the Lem-based formal executable EVM semantics, it performs
favorably when compared to the language-specific reference implementation.
It was under 30 times slower on the stress tests, roughly 20 times
slower on all tests, and only 11 times slower on VMNormal tests.
Note that since the publication of the paper, newer versions
of $\K$ have been introduced with significant performance improvements.

In \cite{HildenbrandtCSF18,ParkFSE18}, we used the $\K$ semantics of the EVM to
build a tool for verification EVM smart contracts. As EVM bytecode is a
low-level stack based language lacking constructs such as functions,
verification of smart contracts proved tedious. To address this, we
introduced a DSL for simulating function calls modeled on the Ethereum ABI
\cite{ethereumAbiUrl} and several EVM-specific abstractions to make verification
scalable. As a result, we could verify several real world smart contracts
satisfied their correctness specifications. Thus, our work allowed to us
to conclude that
\begin{enumerate*}[label=(\roman*)]
  \item the performance of a $\K$ generated intepreter compares favorably to its
  language-specific counterpart,
  \item the $\K$ can be used to implement a language from scratch, i.e. without
  an informal paper based semantics, as in the case of our DSL for calling
  functions at the bytecode level, and,
  \item the verifier can be used on large programs, but may require additional
  work, such as simplification abstractions and lemmas.
\end{enumerate*}

\subsection{Executable Best-Practice Guidelines as $\K$ Definitions}

In \cite{Saxena22TR}, we presented a \CDSS{} for management of
cardiac arrest based on a well known \BPG{} published by the American Heart
Association \cite{AHAUrl}. Recall from section \ref{subsec:cdss} that
\BPGs{} are often expressed using flowchart-like notation. The cardiac arrest
managment \BPG{} also follows the same convention. In our work, we encoded
transitions in \BPG{} flowcharts as $\K$-rules. As $\K$'s
configuration abstraction mechanism enables only relevant parts of the
configuration to be mentioned, we argue that our methodology permits
\emph{succinct} representation of medical knowledge. This is supported by
the fact that our $\K$ definition encoding the \BPG was only a few hundred lines of
code, and could be used to implement an entire \CDSS{}. But, the $\K$ based
\BPG{} proved hard to comprehend, both to computer scientists not familiar with
$\K$, and healthcare professionals. Although this work \emph{failed} to address
the objectives from section \ref{sec:introduction}, it emphasized the importance
of comprehensibility to \HCPs{} for future endeavors.

\subsection{\MediK{}}

